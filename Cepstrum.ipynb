{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\conda\\conda\\envs\\tf-gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.signal import get_window\n",
    "from skimage.util import view_as_windows\n",
    "from utilities.config_handler import get_config\n",
    "from utilities.visualization import plot_spectogram\n",
    "from utilities.learning import split_train_validation, train_model, predict_ae_error_vectors\n",
    "from utilities.detection import detect_reconstruction_anomalies_median,plot_spectogram_anomalies\n",
    "from utilities.preprocessing import  add_noise,load_fft_test_data ,load_fft_train_data,  reshape_to_blocks,persist_object\\\n",
    "    ,load_object,persist_val_stat, load_val_stat ,get_xhdr_sample_rate , compute_fft_train_data , load_raw_data , compute_fft_train_data \\\n",
    ", compute_fft_test_data,trim_iq_basic_block, complex2power\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import mixture\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin_min\n",
    "from scipy.stats import entropy\n",
    "from scipy.signal import medfilt\n",
    "from scipy.signal import welch\n",
    "from scipy.fftpack import fft,rfft,fftshift,fft2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_records = ['CELL_NORM_2', 'CELL_NORM_3', 'CELL_NORM_4']\n",
    "anomal_records = ['CELL_SWP_18MHz_50us_0dB', \\\n",
    "          'CELL_SWP_18MHz_50us_10dB', 'CELL_SWP_18MHz_100us_0dB', 'CELL_SWP_18MHz_100us_10dB']\n",
    "\n",
    "normal_path='iq_data/CELL/normal'\n",
    "anomal_path='iq_data/CELL/anomal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.prog = 'Spectrum Anomaly Detection'\n",
    "parser.description = 'Use this command parser for training or testing the anomaly detector'\n",
    "parser.add_argument('-m', '--mode', help='train or test mode', choices=['train', 'test'])\n",
    "parser.add_argument('-d', '--data-dir', help='I/Q recording directory',nargs='?')\n",
    "parser.add_argument('-w', '--weights-path', help='path for trained weights')\n",
    "\n",
    "\n",
    "sys.argv = \"-m test -d -w model/baseline_cepstrum\".split()\n",
    "# sys.argv = \"-m test -d iq_data/CELL/anomal/CELL_NORM_4 -w model/baseline_cepstrum\".split()\n",
    "# sys.argv = \"-m train -d iq_data/CELL/normal/CELL_NORM_0 -w model/baseline_cepstrum\".split()\n",
    "\n",
    "namespace = parser.parse_args(sys.argv)\n",
    "if not namespace.data_dir and namespace.mode == 'train':\n",
    "    parser.error('the -d arg must be present when mode is train')\n",
    "if not namespace.weights_path and namespace.mode == 'train':\n",
    "    parser.error('the -w arg must be present when mode is train')\n",
    "\n",
    "# if not namespace.data_dir and namespace.mode == 'test':\n",
    "#     parser.error('the -d arg must be present when mode is test')\n",
    "\n",
    "if not namespace.weights_path and namespace.mode == 'test':\n",
    "    parser.error('the -w arg must be present when mode is test')\n",
    "    \n",
    "train = namespace.mode == 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=get_config()\n",
    "gpus = conf['gpus']\n",
    "lr=conf['learning']['ae']['lr']\n",
    "validation_split = conf['learning']['ae']['validation_split']\n",
    "train_params = conf['learning']['ae']\n",
    "rbw_set = conf['preprocessing']['ae']['rbw_set']\n",
    "feature_names = conf['preprocessing']['ae']['feature_names']\n",
    "fft_window_name = conf['preprocessing']['ae']['window']\n",
    "basic_block_interval = conf['preprocessing']['basic_time']\n",
    "\n",
    "\n",
    "median_kernel_size = 11\n",
    "cepstrum_window_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_frequency_spectrum(freq):\n",
    "    num_samples = len(freq)\n",
    "    freq = freq - np.mean(freq)\n",
    "    window = get_window(fft_window_name, num_samples)\n",
    "    fft_data = ((rfft(window*freq)))\n",
    "    return fft_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_welch_spectrum(freq):\n",
    "    freq = freq - np.mean(freq)\n",
    "    return welch(freq,len(freq*(1/basic_block_interval)) , nperseg=cepstrum_window_size , \\\n",
    "      noverlap=3*cepstrum_window_size//4 , scaling = 'spectrum',window='hann')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cepstrum(data_dir,rbw):\n",
    "    dataset_name = str.split(data_dir, '/')[1]\n",
    "    recording_name = str.split(data_dir,'/')[-1]\n",
    "    sample_rate = get_xhdr_sample_rate(data_dir)\n",
    "    weights_dir = \"_\".join((dataset_name, str(rbw)))\n",
    "    weights_path = os.path.join(namespace.weights_path, weights_dir)\n",
    "\n",
    "    iq_data = load_raw_data(data_dir)\n",
    "    iq_data = trim_iq_basic_block(iq_data , sample_rate)\n",
    "    freqs, time, fft_train = compute_fft_train_data(iq_data,sample_rate,rbw,weights_path)\n",
    "    cepstrum_train = np.abs(np.apply_along_axis(compute_welch_spectrum,0,fft_train))\n",
    "    cepstrum_train = cepstrum_train[50:] # removing the zero frequency\n",
    "    cepstrum_train_means_over_time = np.mean(cepstrum_train,axis=1)\n",
    "    cepstrum_windows = view_as_windows(cepstrum_train_means_over_time,median_kernel_size,step=1)\n",
    "    cepstrum_train_means_over_time = np.apply_along_axis(lambda x: x - np.median(x),1,cepstrum_windows).reshape(-1)\n",
    "    cepstrum_train_max = np.max(cepstrum_train_means_over_time)\n",
    "    persist_object(cepstrum_train_max,os.path.join(weights_path,'cepstrum_max.pkl'))\n",
    "    persist_object(cepstrum_train_means_over_time,os.path.join(weights_path,'cepstrum_train_means.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cepstrum(data_dir,rbw):\n",
    "    sample_rate = get_xhdr_sample_rate(data_dir)\n",
    "    dataset_name = str.split(data_dir, '/')[1]\n",
    "    recording_name = str.split(data_dir,'/')[-1]\n",
    "    weights_dir = \"_\".join((dataset_name, str(rbw)))\n",
    "    weights_path = os.path.join(namespace.weights_path, weights_dir)\n",
    "    \n",
    "    iq_data = load_raw_data(data_dir)\n",
    "    iq_data = trim_iq_basic_block(iq_data , sample_rate)\n",
    "    test_freqs, test_time, fft_test = compute_fft_test_data(iq_data,sample_rate,rbw,weights_path)\n",
    "    cepstrum_test = np.abs(np.apply_along_axis(compute_welch_spectrum,0,fft_test))\n",
    "    cepstrum_test = cepstrum_test[50:] # removing the zero frequency\n",
    "    cepstrum_test_means_over_time = np.mean(cepstrum_test,axis=1)\n",
    "    cepstrum_train_max = load_object(os.path.join(weights_path,'cepstrum_max.pkl'))\n",
    "    cepstrum_train_means_over_time = load_object(os.path.join(weights_path,'cepstrum_train_means.pkl'))\n",
    "    \n",
    "    cepstrum_windows = view_as_windows(cepstrum_test_means_over_time,median_kernel_size,step=1)\n",
    "    cepstrum_test_means_over_time = np.apply_along_axis(lambda x: x - np.median(x),1,cepstrum_windows).reshape(-1)\n",
    "\n",
    "    fig , (ax1 , ax2) = plt.subplots(1,2,sharey=True,figsize=(20,15))\n",
    "    ax1.axhline(cepstrum_train_max)\n",
    "    ax1.plot(cepstrum_test_means_over_time)\n",
    "    ax1.set_title('Test cepstrum',fontsize=30)\n",
    "    ax2.axhline(cepstrum_train_max)\n",
    "    ax2.plot(cepstrum_train_means_over_time)\n",
    "    ax2.set_title('Train cepstrum' , fontsize=30)\n",
    "    plot_save_path = os.path.join(data_dir , \"cepstrum_welch_window={}_interval={}.png\".\\\n",
    "                                  format(cepstrum_window_size,basic_block_interval))\n",
    "    plt.savefig(plot_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\conda\\conda\\envs\\tf-gpu\\lib\\site-packages\\scipy\\signal\\spectral.py:1785: UserWarning: nperseg = 512 is greater than input length  = 497, using nperseg = 497\n",
      "  .format(nperseg, input_length))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model/baseline_cepstrum\\\\CELL_125000.0\\\\cepstrum_max.pkl'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-04e6f6adad1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormal_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mrbw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrbw_set\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                 \u001b[0mtest_cepstrum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrbw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manomal_records\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-50ee90946ec2>\u001b[0m in \u001b[0;36mtest_cepstrum\u001b[1;34m(data_dir, rbw)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mcepstrum_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcepstrum_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# removing the zero frequency\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mcepstrum_test_means_over_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcepstrum_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mcepstrum_train_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'cepstrum_max.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mcepstrum_train_means_over_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'cepstrum_train_means.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\spectrum_analysis\\utilities\\preprocessing.py\u001b[0m in \u001b[0;36mload_object\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mxdat2array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxdat_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlittle_endian\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\conda\\conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_basestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model/baseline_cepstrum\\\\CELL_125000.0\\\\cepstrum_max.pkl'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "if train:\n",
    "    data_dir = namespace.data_dir\n",
    "    for rbw in rbw_set:\n",
    "        train_cepstrum(data_dir,rbw)\n",
    "        \n",
    "else:\n",
    "    #Case we evaluate on set of fixed test sets\n",
    "    if not namespace.data_dir:\n",
    "        for r in normal_records:\n",
    "            data_dir = os.path.join(normal_path, r)\n",
    "            for rbw in rbw_set:\n",
    "                test_cepstrum(data_dir,rbw)\n",
    "                \n",
    "        for r in anomal_records:\n",
    "            data_dir = os.path.join(anomal_path,r)\n",
    "            f_s = get_xhdr_sample_rate(data_dir)\n",
    "            for rbw in rbw_set:\n",
    "                test_cepstrum(data_dir,rbw)\n",
    "    else:\n",
    "        data_dir = namespace.data_dir\n",
    "        assert len(data_dir) != 0\n",
    "        for rbw in rbw_set:\n",
    "            test_cepstrum(data_dir,rbw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sweep_freq = fft_train[:,250] - np.mean(fft_train[:,250])\n",
    "fig , (ax1 , ax2) = plt.subplots(2,1,figsize=(10,10))\n",
    "cepstrum_sample_plot_path = os.path.join(data_dir,\"cepstrum_sample.png\")\n",
    "ax1.plot(sweep_freq)\n",
    "ax1.set_title('Sweep frequency plot')\n",
    "ax2.plot(np.abs(compute_frequency_spectrum(sweep_freq)))\n",
    "ax2.set_title('fft of frequency')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
