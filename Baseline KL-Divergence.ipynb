{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.util import view_as_windows\n",
    "from utilities.config_handler import get_config\n",
    "from utilities.learning import split_train_validation, train_model, predict_ae_error_vectors\n",
    "from utilities.detection import detect_reconstruction_anomalies_median,plot_spectogram_anomalies\n",
    "from utilities.preprocessing import  add_noise,load_fft_test_data ,load_fft_train_data,  reshape_to_blocks,persist_object\\\n",
    "    ,load_object,persist_val_stat, load_val_stat ,get_xhdr_sample_rate\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.prog = 'Spectrum Anomaly Detection'\n",
    "parser.description = 'Use this command parser for training or testing the anomaly detector'\n",
    "parser.add_argument('-m', '--mode', help='train or test mode', choices=['train', 'test'])\n",
    "parser.add_argument('-d', '--data-dir', help='I/Q recording directory')\n",
    "parser.add_argument('-w', '--weights-path', help='path for trained weights')\n",
    "\n",
    "\n",
    "sys.argv = \"-m test -d iq_data/CELL/anomal -w model/baseline\".split()\n",
    "namespace = parser.parse_args(sys.argv)\n",
    "if not namespace.data_dir and namespace.mode == 'train':\n",
    "    parser.error('the -d arg must be present when mode is train')\n",
    "if not namespace.weights_path and namespace.mode == 'train':\n",
    "    parser.error('the -w arg must be present when mode is train')\n",
    "\n",
    "if not namespace.data_dir and namespace.mode == 'test':\n",
    "    parser.error('the -d arg must be present when mode is test')\n",
    "if not namespace.weights_path and namespace.mode == 'test':\n",
    "    parser.error('the -w arg must be present when mode is test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=get_config()\n",
    "gpus = conf['gpus']\n",
    "lr=conf['learning']['ae']['lr']\n",
    "validation_split = conf['learning']['ae']['validation_split']\n",
    "train_params = conf['learning']['ae']\n",
    "rbw_set = conf['preprocessing']['ae']['rbw_set']\n",
    "feature_names = conf['preprocessing']['ae']['feature_names']\n",
    "train = namespace.mode == 'train'\n",
    "\n",
    "\n",
    "data_dir = namespace.data_dir\n",
    "\n",
    "f_s = get_xhdr_sample_rate(data_dir)\n",
    "t_s = 1/f_s\n",
    "test_window_time = 10e-6\n",
    "\n",
    "window_height = int(test_window_time / * t_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251410500"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fft_test.shape[0]* fft_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78125000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6103515625"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fft_len = 1024\n",
    "row_len_sec = fft_len * t_s\n",
    "total_rows = fft_test.size / fft_len;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78124999999.0, 502821)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`window_shape` is too large",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1c84880e63a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mfft_test_windows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mview_as_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfft_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindow_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow_height\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#         divergences = np.zeros(len(fft_ref))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/spectrum/lib/python3.5/site-packages/skimage/util/shape.py\u001b[0m in \u001b[0;36mview_as_windows\u001b[0;34m(arr_in, window_shape, step)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_shape\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwindow_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`window_shape` is too large\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_shape\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `window_shape` is too large"
     ]
    }
   ],
   "source": [
    "assert len(data_dir) != 0\n",
    "dataset_name = str.split(data_dir, '/')[-2]\n",
    "if train:\n",
    "    for rbw in rbw_set:\n",
    "        weights_dir = \"_\".join((dataset_name,str(rbw)))\n",
    "        weights_path = os.path.join(namespace.weights_path,weights_dir)\n",
    "        fft_train = load_fft_train_data(data_dir, rbw, weights_path)\n",
    "        fft_train = fft_train.T\n",
    "        fft_train = fft_train/fft_train.sum(axis=1,keepdims=1)\n",
    "        persist_object(fft_train,os.path.join(weights_path,\"reference.pkl\"))\n",
    "\n",
    "else:\n",
    "    for rbw in rbw_set:\n",
    "        weights_dir = \"_\".join((dataset_name,str(rbw)))\n",
    "        weights_load_path = os.path.join(namespace.weights_path,weights_dir)\n",
    "        fft_test = load_fft_test_data(data_dir , rbw, weights_load_path)\n",
    "        fft_test = fft_test.T\n",
    "        fft_test = fft_test/fft_test.sum(axis=1,keepdims=1)\n",
    "        fft_ref = load_object(os.path.join(weights_load_path,'reference.pkl'))\n",
    "        \n",
    "        #Define the windows size\n",
    "        window_height = test_window_time // ((1/rbw) * t_s)\n",
    "        window_width = fft_test.shape[1]\n",
    "        window_shape = (window_height , window_width)\n",
    "        print(window_shape)\n",
    "        \n",
    "        fft_test_windows = view_as_windows(fft_test,window_shape,step = window_height//2)\n",
    "                \n",
    "#         divergences = np.zeros(len(fft_ref))\n",
    "#         for i in range(len(divergences)):\n",
    "#             divergences[i] = entropy(fft_test[i,:] , fft_ref[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_iqr(ys):\n",
    "    quartile_1, quartile_3 = np.percentile(ys, [25, 75])\n",
    "    iqr = quartile_3 - quartile_1\n",
    "    lower_bound = quartile_1 - (iqr * 1.5)\n",
    "    upper_bound = quartile_3 + (iqr * 1.5)\n",
    "    return np.where((ys > upper_bound) | (ys < lower_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = outliers_iqr(divergences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
