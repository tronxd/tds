{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.util import view_as_windows\n",
    "from utilities.config_handler import get_config\n",
    "from utilities.learning import split_train_validation, train_model, predict_ae_error_vectors\n",
    "from utilities.detection import detect_reconstruction_anomalies_median,plot_spectogram_anomalies\n",
    "from utilities.preprocessing import  add_noise,load_fft_test_data ,load_fft_train_data,  reshape_to_blocks,persist_object\\\n",
    "    ,load_object,persist_val_stat, load_val_stat ,get_xhdr_sample_rate\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.prog = 'Spectrum Anomaly Detection'\n",
    "parser.description = 'Use this command parser for training or testing the anomaly detector'\n",
    "parser.add_argument('-m', '--mode', help='train or test mode', choices=['train', 'test'])\n",
    "parser.add_argument('-d', '--data-dir', help='I/Q recording directory')\n",
    "parser.add_argument('-w', '--weights-path', help='path for trained weights')\n",
    "\n",
    "\n",
    "sys.argv = \"-m test -d iq_data/CELL/anomal -w model/baseline\".split()\n",
    "namespace = parser.parse_args(sys.argv)\n",
    "if not namespace.data_dir and namespace.mode == 'train':\n",
    "    parser.error('the -d arg must be present when mode is train')\n",
    "if not namespace.weights_path and namespace.mode == 'train':\n",
    "    parser.error('the -w arg must be present when mode is train')\n",
    "\n",
    "if not namespace.data_dir and namespace.mode == 'test':\n",
    "    parser.error('the -d arg must be present when mode is test')\n",
    "if not namespace.weights_path and namespace.mode == 'test':\n",
    "    parser.error('the -w arg must be present when mode is test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=get_config()\n",
    "gpus = conf['gpus']\n",
    "lr=conf['learning']['ae']['lr']\n",
    "validation_split = conf['learning']['ae']['validation_split']\n",
    "train_params = conf['learning']['ae']\n",
    "rbw_set = conf['preprocessing']['ae']['rbw_set']\n",
    "feature_names = conf['preprocessing']['ae']['feature_names']\n",
    "train = namespace.mode == 'train'\n",
    "\n",
    "\n",
    "data_dir = namespace.data_dir\n",
    "\n",
    "f_s = get_xhdr_sample_rate(data_dir)\n",
    "t_s = 1/f_s\n",
    "test_window_time = 10e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'fft_test_scaled' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5964232aa041>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mweights_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrbw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mweights_load_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mfreqs_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfft_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_fft_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mrbw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_load_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mfft_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfft_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/spectrum_analysis/utilities/preprocessing.py\u001b[0m in \u001b[0;36mload_fft_test_data\u001b[0;34m(test_data_dir, rbw, weights_dir)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_scaling\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mfft_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_test_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfft_test\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mscaler_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfft_test_scaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscale_train_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'fft_test_scaled' referenced before assignment"
     ]
    }
   ],
   "source": [
    "assert len(data_dir) != 0\n",
    "dataset_name = str.split(data_dir, '/')[-2]\n",
    "if train:\n",
    "    for rbw in rbw_set:\n",
    "        weights_dir = \"_\".join((dataset_name,str(rbw)))\n",
    "        weights_path = os.path.join(namespace.weights_path,weights_dir)\n",
    "        fft_train  = load_fft_train_data(data_dir, rbw, weights_path)\n",
    "        \n",
    "        fft_train = fft_train.T\n",
    "        fft_train = fft_train/fft_train.sum(axis=1,keepdims=1)\n",
    "        persist_object(fft_train,os.path.join(weights_path,\"reference_spectogram.pkl\"))\n",
    "\n",
    "else:\n",
    "    for rbw in rbw_set:\n",
    "        weights_dir = \"_\".join((dataset_name,str(rbw)))\n",
    "        weights_load_path = os.path.join(namespace.weights_path,weights_dir)\n",
    "        freqs_test, time_test, fft_test = load_fft_test_data(data_dir , rbw, weights_load_path)\n",
    "        \n",
    "        fft_test = fft_test.T\n",
    "        fft_test = fft_test/fft_test.sum(axis=1,keepdims=1)\n",
    "        fft_ref = load_object(os.path.join(weights_load_path,'reference.pkl'))\n",
    "        \n",
    "        #Define the windows size\n",
    "#         window_width = fft_test.shape[1]\n",
    "#         window_shape = (window_height , window_width)\n",
    "#         print(window_shape)\n",
    "        \n",
    "        #fft_test_windows = view_as_windows(fft_test,window_shape,step = window_height//2)\n",
    "                \n",
    "#         divergences = np.zeros(len(fft_ref))\n",
    "#         for i in range(len(divergences)):\n",
    "#             divergences[i] = entropy(fft_test[i,:] , fft_ref[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_iqr(ys):\n",
    "    quartile_1, quartile_3 = np.percentile(ys, [25, 75])\n",
    "    iqr = quartile_3 - quartile_1\n",
    "    lower_bound = quartile_1 - (iqr * 1.5)\n",
    "    upper_bound = quartile_3 + (iqr * 1.5)\n",
    "    return np.where((ys > upper_bound) | (ys < lower_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = outliers_iqr(divergences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
