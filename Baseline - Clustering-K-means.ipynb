{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.util import view_as_windows\n",
    "from utilities.config_handler import get_config\n",
    "from utilities.learning import split_train_validation, train_model, predict_ae_error_vectors\n",
    "from utilities.detection import detect_reconstruction_anomalies_median,plot_spectogram_anomalies\n",
    "from utilities.preprocessing import  add_noise,load_fft_test_data ,load_fft_train_data,  reshape_to_blocks,persist_object\\\n",
    "    ,load_object,persist_val_stat, load_val_stat ,get_xhdr_sample_rate , compute_fft_train_data , load_raw_data , compute_fft_train_data \\\n",
    ", compute_fft_test_data,trim_iq_basic_block, complex2power\n",
    "compute_fft_train_data\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import mixture\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin_min\n",
    "import pandas as pd\n",
    "from utilities.visualization import plot_spectogram\n",
    "from scipy.stats import entropy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_records = ['CELL_NORM_0', 'CELL_NORM_3', 'CELL_NORM_4']\n",
    "anomal_records = ['CELL_SWP_18MHz_50us_0dB', \\\n",
    "          'CELL_SWP_18MHz_50us_10dB', 'CELL_SWP_18MHz_100us_0dB', 'CELL_SWP_18MHz_100us_10dB']\n",
    "\n",
    "normal_path='iq_data/CELL/normal'\n",
    "anomal_path='iq_data/CELL/anomal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.prog = 'Spectrum Anomaly Detection'\n",
    "parser.description = 'Use this command parser for training or testing the anomaly detector'\n",
    "parser.add_argument('-m', '--mode', help='train or test mode', choices=['train', 'test'])\n",
    "parser.add_argument('-d', '--data-dir', help='I/Q recording directory',nargs='?')\n",
    "parser.add_argument('-w', '--weights-path', help='path for trained weights')\n",
    "\n",
    "\n",
    "sys.argv = \"-m test -d -w model/baseline_kmeans\".split()\n",
    "# sys.argv = \"-m test -d iq_data/CELL/anomal/CELL_NORM_4 -w model/baseline_kmeans\".split()\n",
    "# sys.argv = \"-m train -d iq_data/CELL/normal/CELL_NORM_2 -w model/baseline_kmeans\".split()\n",
    "\n",
    "namespace = parser.parse_args(sys.argv)\n",
    "if not namespace.data_dir and namespace.mode == 'train':\n",
    "    parser.error('the -d arg must be present when mode is train')\n",
    "if not namespace.weights_path and namespace.mode == 'train':\n",
    "    parser.error('the -w arg must be present when mode is train')\n",
    "\n",
    "# if not namespace.data_dir and namespace.mode == 'test':\n",
    "#     parser.error('the -d arg must be present when mode is test')\n",
    "\n",
    "if not namespace.weights_path and namespace.mode == 'test':\n",
    "    parser.error('the -w arg must be present when mode is test')\n",
    "    \n",
    "train = namespace.mode == 'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=get_config()\n",
    "gpus = conf['gpus']\n",
    "lr=conf['learning']['ae']['lr']\n",
    "validation_split = conf['learning']['ae']['validation_split']\n",
    "train_params = conf['learning']['ae']\n",
    "rbw_set = conf['preprocessing']['ae']['rbw_set']\n",
    "feature_names = conf['preprocessing']['ae']['feature_names']\n",
    "train = namespace.mode == 'train'\n",
    "\n",
    "\n",
    "atom_height = 1\n",
    "num_clusters_set = [250,500,750]\n",
    "cv_types = ['diag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_spectogram_to_atoms(spectogram,atom_height,stride=1):\n",
    "    window_shape = (atom_height , spectogram.shape[1])\n",
    "    return view_as_windows(spectogram,window_shape,step=stride).reshape(-1,*window_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_spectogram_by_fraction(spectogram,frac):\n",
    "    return spectogram[:int(frac*len(spectogram))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consecutive(data, stepsize=1):\n",
    "    return [list(part) for part in np.split(data, np.where(np.diff(data) != stepsize)[0]+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_k_means(data_dir,rbw,num_clusters):\n",
    "    assert len(data_dir) != 0\n",
    "    dataset_name = str.split(data_dir, '/')[1]\n",
    "    recording_name = str.split(data_dir,'/')[-1]\n",
    "    weights_dir = \"_\".join((dataset_name, str(rbw)))\n",
    "    weights_path = os.path.join(namespace.weights_path, weights_dir)\n",
    "    sample_rate = get_xhdr_sample_rate(data_dir)\n",
    "    iq_data = load_raw_data(data_dir)\n",
    "    iq_data = trim_iq_basic_block(iq_data , sample_rate)\n",
    "    freqs, time, fft_train = compute_fft_train_data(iq_data,sample_rate,rbw,weights_path)\n",
    "    print(\"Spectrogram length: {}\".format(len(fft_train)))\n",
    "    atom_fft_train = split_spectogram_to_atoms(fft_train,atom_height)\n",
    "    flatten_atom_fft_train = atom_fft_train.reshape(len(atom_fft_train),-1)\n",
    "\n",
    "    k_means = fit_kmeans(flatten_atom_fft_train,num_clusters)\n",
    "    (min_clusters_train,min_distances_train) = pairwise_distances_argmin_min(\\\n",
    "                                                flatten_atom_fft_train,k_means.cluster_centers_,metric='euclidean')\n",
    "\n",
    "    train_clusters_distances_df = pd.DataFrame({'cluster':min_clusters_train , 'distance':min_distances_train})\n",
    "    max_cluster_distance_train = train_clusters_distances_df.groupby('cluster').max()\n",
    "    persist_object(k_means,os.path.join(weights_path,'k_means_k={}_a={}.pkl'.format(num_clusters,atom_height)))\n",
    "    persist_object(train_clusters_distances_df,os.path.join(weights_path,\\\n",
    "                                        'train_clusters_distances_k={}_a={}.pkl'.format(num_clusters,atom_height)))\n",
    "    persist_object(max_cluster_distance_train , os.path.join(weights_path,\\\n",
    "                                             'max_cluster_distance_k={}_a={}.pkl'.format(num_clusters,atom_height)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_k_means(data_dir,rbw,num_clusters):\n",
    "    assert len(data_dir) != 0\n",
    "    dataset_name = str.split(data_dir, '/')[1]\n",
    "    recording_name = str.split(data_dir,'/')[-1]\n",
    "    weights_dir = \"_\".join((dataset_name, str(rbw)))\n",
    "    weights_path = os.path.join(namespace.weights_path, weights_dir)\n",
    "    sample_rate = get_xhdr_sample_rate(data_dir)\n",
    "    \n",
    "    iq_data = load_raw_data(data_dir)\n",
    "    iq_data = trim_iq_basic_block(iq_data , sample_rate)\n",
    "    test_freqs, test_time, fft_test = compute_fft_test_data(iq_data,sample_rate,rbw,weights_path)\n",
    "    \n",
    "    atom_fft_test = split_spectogram_to_atoms(fft_test,atom_height)\n",
    "    flatten_atom_fft_test = atom_fft_test.reshape(len(atom_fft_test),-1)\n",
    "    k_means = load_object(os.path.join(weights_path,'k_means_k={}_a={}.pkl'.format(num_clusters,atom_height)))\n",
    "    train_clusters_distances_df = load_object(os.path.join(weights_path,'train_clusters_distances_k={}_a={}.pkl'\\\n",
    "                                                   .format(num_clusters,atom_height)))\n",
    "\n",
    "    max_cluster_distance_train = load_object(os.path.join(weights_path,\\\n",
    "                                             'max_cluster_distance_k={}_a={}.pkl'.format(num_clusters,atom_height)))\n",
    "\n",
    "    window_shape = (atom_height , atom_fft_test.shape[1] // atom_height)\n",
    "    score_spectogram = np.ones_like(atom_fft_test)\n",
    "    (min_clusters_test,min_distances_test) = pairwise_distances_argmin_min(flatten_atom_fft_test,\\\n",
    "                                                                           k_means.cluster_centers_,\\\n",
    "                                                                            metric='euclidean')\n",
    "\n",
    "    test_clusters_distances_df = pd.DataFrame({'cluster':min_clusters_test , 'distance':min_distances_test})\n",
    "    test_clusters_distances_df['anomaly'] = test_clusters_distances_df\\\n",
    "                            .apply(lambda x : x.distance > max_cluster_distance_train.iloc[int(x.cluster)] , axis=1)\n",
    "\n",
    "    anomalies_indices = np.argwhere(test_clusters_distances_df.anomaly).squeeze().tolist()\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(10,10))\n",
    "    percent_anomalies = len(anomalies_indices) / len(test_clusters_distances_df) * 100\n",
    "    ax.plot(np.sort(min_distances_test))\n",
    "#         for index, row in max_cluster_distance_train.iterrows():\n",
    "#             ax.axhline(row.distance,color='r',linewidth=0.1)\n",
    "\n",
    "    ax.set_title('Test minimum distances, num clusters {0:d} ,atom height {1}, num anomolous atoms {2:.2f}%'.\\\n",
    "                  format(num_clusters,atom_height,percent_anomalies))\n",
    "\n",
    "    distances_plot_path = os.path.join(data_dir ,'cluster_distances_k={}_a={}_{}.png'.\\\n",
    "                                       format(num_clusters,atom_height,recording_name))\n",
    "    plt.savefig(distances_plot_path)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,20))\n",
    "    anomalies_blocks = consecutive(anomalies_indices)\n",
    "    ax.imshow(fft_test,aspect='auto', origin='upper')\n",
    "    if len(anomalies_indices) > 0:\n",
    "        anomalies_plot_path = os.path.join(data_dir ,'cluster_anomalies_k={}_a={}_{}.png'.\\\n",
    "                                       format(num_clusters,atom_height,recording_name))\n",
    "        for block in anomalies_blocks:\n",
    "            x_cord = 0\n",
    "            y_cord = block[0]\n",
    "            block_height , block_width = len(block) + 1,fft_test.shape[1]\n",
    "            rect = patches.Rectangle((x_cord,y_cord),block_width-1,block_height,edgecolor='r',\\\n",
    "                                     facecolor='r',fill=True,alpha=0.5,linewidth=0.1,rasterized=True)\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "    plt.savefig(anomalies_plot_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    data_dir=namespace.data_dir\n",
    "    for rbw in rbw_set:\n",
    "        for num_clusters in num_clusters_set:\n",
    "            train_k_means(data_dir,rbw,num_clusters)\n",
    "            \n",
    "else:\n",
    "    \n",
    "    if not namespace.data_dir:\n",
    "        for r in normal_records:\n",
    "            data_dir = os.path.join(normal_path, r)\n",
    "            for rbw in rbw_set:\n",
    "                for num_clusters in num_clusters_set:\n",
    "                    test_k_means(data_dir,rbw,num_clusters)\n",
    "\n",
    "        for r in anomal_records:\n",
    "            data_dir = os.path.join(anomal_path,r)\n",
    "            for rbw in rbw_set:\n",
    "                for num_clusters in num_clusters_set:\n",
    "                    test_k_means(data_dir,rbw,num_clusters)\n",
    "\n",
    "    else:\n",
    "        data_dir = namespace.data_dir\n",
    "        assert len(data_dir) != 0\n",
    "        for rbw in rbw_set:\n",
    "            for num_clusters in num_clusters_set:\n",
    "                test_k_means(data_dir,rbw,num_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrum visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
